{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_patches.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLwU0VXpMpwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.misc\n",
        "import imageio\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "\n",
        "def get_image_patch_coord(size_x, size_y, patch_size):\n",
        "    \"\"\" Generates overlapping patches from an image. \"\"\"\n",
        "    step = patch_size // 2\n",
        "    nx = (size_x-patch_size) // step + 1\n",
        "    ny = (size_y-patch_size) // step + 1\n",
        "    patch_coord = np.ndarray(shape=(nx*ny, 2), dtype=np.int32)\n",
        "    i = 0\n",
        "    for y in range(0, size_y-patch_size, step):\n",
        "        for x in range(0, size_x-patch_size, step):\n",
        "            patch_coord[i] = [x, y]\n",
        "            i += 1\n",
        "    return patch_coord[:i]\n",
        "\n",
        "def load_mask(fullmask):\n",
        "    mask = Image.open(fullmask)\n",
        "    return np.array(mask)\n",
        "\n",
        "def get_patch_label(i0, j0, patch_size, mask, n_class=4):\n",
        "    ws = patch_size // 3\n",
        "    central_grades = mask[(i0+ws):(i0+2*ws), (j0+ws):(j0+2*ws)]\n",
        "    grades_found = np.unique(central_grades)\n",
        "    grades_found = grades_found[grades_found < n_class]\n",
        "    grade = grades_found[0] if len(grades_found) == 1 else n_class\n",
        "    return grade\n",
        "\n",
        "def open_jpg(img):\n",
        "    return imageio.imread(img)\n",
        "\n",
        "def is_too_white(img, limit=190):\n",
        "    return np.mean(img) > limit\n",
        "\n",
        "def save_patch(patch, saving_name):\n",
        "    image = Image.fromarray(patch)\n",
        "    image.save(saving_name)\n",
        "\n",
        "def sum_up_gleason(maskfile, n_class=4):\n",
        "    # read the mask and count the grades\n",
        "    mask = load_mask(maskfile)\n",
        "    c = Counter(mask.flatten())\n",
        "    grade_count = np.zeros(n_class, dtype=int)\n",
        "    for i in range(n_class):\n",
        "        grade_count[i] = c[i]\n",
        "\n",
        "    # get the max and second max scores and write them to file\n",
        "    idx = np.argsort(grade_count)\n",
        "    primary_score = idx[-1]\n",
        "    secondary_score = idx[-2]\n",
        "    if np.sum(grade_count == 0) == 3:\n",
        "        secondary_score = primary_score\n",
        "    return primary_score, secondary_score\n",
        "\n",
        "\n",
        "class ImageProcessor():\n",
        "    def __init__(self, path_images, path_masks, path_patches):\n",
        "        self.path_images = path_images\n",
        "        self.path_patches = path_patches\n",
        "        self.path_masks = path_masks\n",
        "        self.palette = [0, 255, 0, # benign is green (index 0)\n",
        "                        0, 0, 255, # Gleason 3 is blue (index 1)\n",
        "                        255, 255, 0, # Gleason 4 is yellow (index 2)\n",
        "                        255, 0, 0, # Gleason 5 is red (index 3)\n",
        "                        255, 255, 255] # ignore class is white (index 4)\n",
        "        if not os.path.exists(self.path_masks):\n",
        "            os.makedirs(self.path_masks)\n",
        "        if not os.path.exists(self.path_patches):\n",
        "            os.makedirs(self.path_patches)\n",
        "\n",
        "\n",
        "    def create_annotated_patches(self, pcsv_file, tma_pref, patch_size, n_class=4):\n",
        "        # loop over images\n",
        "        print(\"parches train\",tma_pref)\n",
        "        f_pout = open(pcsv_file, 'w')\n",
        "        print('%s\\t%s' % ('patch_name', 'grade_'), file=f_pout)\n",
        "        for filename1 in os.listdir(self.path_images):\n",
        "            if filename1.startswith(tma_pref):\n",
        "                imgs = os.path.join(self.path_images,filename1)\n",
        "                for filename in os.listdir(imgs):\n",
        "                        name = filename.rstrip('.jpg')\n",
        "                        fullmask = os.path.join(self.path_masks, 'mask_' + name + '.png')\n",
        "                        if os.path.exists(fullmask):\n",
        "                            subdir = os.path.join(self.path_patches, name)\n",
        "                            os.makedirs(subdir)\n",
        "\n",
        "                            # read the image\n",
        "                            fullname = os.path.join(imgs, filename)\n",
        "                            img = open_jpg(fullname)\n",
        "                            size_y, size_x = img.shape[0], img.shape[1]\n",
        "                            # load the mask\n",
        "                            mask = load_mask(fullmask)\n",
        "\n",
        "                            patch_coord = get_image_patch_coord(size_x, size_y, patch_size)\n",
        "                            for j, (i_0, j_0) in enumerate(patch_coord):\n",
        "                                patch = img[i_0:i_0+patch_size, j_0:j_0+patch_size]\n",
        "                                grade = get_patch_label(i_0, j_0, patch_size, mask)\n",
        "                                # if the patch was annotated with a single Gleason grade\n",
        "                                # and does not contain mostly background,\n",
        "                                # then save it\n",
        "                                if (grade < n_class) and (not is_too_white(patch, limit=180)):\n",
        "                                    patch_name = os.path.join(subdir, '%s_patch_%d_class_%d.jpg' % (name, j, grade))\n",
        "                                    pname = name + \"_patch_\" + str(j) + \"_class_\" + str(grade) + \".jpg\"\n",
        "                                    print('%s\\t%d' % (patch_name, grade), file=f_pout)\n",
        "                                    save_patch(patch, patch_name)\n",
        "        f_pout.close()\n",
        "\n",
        "\n",
        "    def create_joint_patches(self, pcsv_file, tma_pref, patch_size, csv_file, n_class=4):\n",
        "        # subdirectories, one for each pathologist\n",
        "        print(\"parches test\")\n",
        "        subdir_patho_1 = os.path.join(self.path_patches, 'patho_1')\n",
        "        subdir_patho_2 = os.path.join(self.path_patches, 'patho_2')\n",
        "        os.makedirs(subdir_patho_1)\n",
        "        os.makedirs(subdir_patho_2)\n",
        "        mask_dir_1 = os.path.join(self.path_masks, 'Gleason_masks_test_pathologist1')\n",
        "        mask_dir_2 = os.path.join(self.path_masks, 'Gleason_masks_test_pathologist2')\n",
        "\n",
        "        # open a file for writing down the grades\n",
        "        f_out = open(csv_file, 'w')\n",
        "        f_pout = open(pcsv_file, 'w')\n",
        "        print('%s\\t%s\\t%s' % ('patch_name', 'grade_1', 'grade_2'), file=f_out)\n",
        "        print('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s' % ('patch_name1', 'grade_1', 'x_cord1' , 'y_cord1' , 'patch_name2', 'grade_2' , 'x_cord2' , 'y_cord2'), file=f_pout)\n",
        "        # loop over images\n",
        "        for filename1 in os.listdir(self.path_images):\n",
        "            if filename1.startswith(tma_pref):\n",
        "                imgs = os.path.join(self.path_images,filename1)\n",
        "                for filename in os.listdir(imgs):\n",
        "                    name = filename.rstrip('.jpg')\n",
        "                    fullmask_1 = os.path.join(mask_dir_1, 'mask1_' + name + '.png')\n",
        "                    fullmask_2 = os.path.join(mask_dir_2, 'mask2_' + name + '.png')\n",
        "\n",
        "                # if an annotation exists by both pathologists\n",
        "                    if os.path.exists(fullmask_1) and os.path.exists(fullmask_2):\n",
        "                        dir_1 = os.path.join(subdir_patho_1, name)\n",
        "                        dir_2 = os.path.join(subdir_patho_2, name)\n",
        "                        os.makedirs(dir_1)\n",
        "                        os.makedirs(dir_2)\n",
        "\n",
        "                        # read the image\n",
        "                        fullname = os.path.join(imgs, filename)\n",
        "                        img = open_jpg(fullname)\n",
        "                        size_y, size_x = img.shape[0], img.shape[1]\n",
        "                        # load the masks\n",
        "                        mask_1 = load_mask(fullmask_1)\n",
        "                        mask_2 = load_mask(fullmask_2)\n",
        "\n",
        "                        patch_coord = get_image_patch_coord(size_x, size_y, patch_size)\n",
        "                        for j, (i_0, j_0) in enumerate(patch_coord):\n",
        "                            grade_1 = get_patch_label(i_0, j_0, patch_size, mask_1)\n",
        "                            grade_2 = get_patch_label(i_0, j_0, patch_size, mask_2)\n",
        "                            # if the patch was annotated by both pathologists\n",
        "                            if (grade_1 < n_class) and (grade_2 < n_class):\n",
        "                                patch = img[i_0:i_0+patch_size, j_0:j_0+patch_size]\n",
        "                                # and it does not contain mostly background\n",
        "                                if not is_too_white(patch, limit=180):\n",
        "                                    # save the patch\n",
        "                                    patch_name_1 = os.path.join(dir_1, '%s_patch_%d_class_%d.jpg' % (name, j, grade_1))\n",
        "                                    patch_name_2 = os.path.join(dir_2, '%s_patch_%d_class_%d.jpg' % (name, j, grade_2))\n",
        "                                    save_patch(patch, patch_name_1)\n",
        "                                    save_patch(patch, patch_name_2)\n",
        "                                    # write down the patch labels\n",
        "                                    pname1 = name + \"_patch_\" + str(j) + \"_class_\" + str(grade_1) + \".jpg\"\n",
        "                                    pname2 = name + \"_patch_\" + str(j) + \"_class_\" + str(grade_2) + \".jpg\"\n",
        "                                    print('%s\\t%d\\t%d\\t%d\\t%s\\t%d\\t%d\\t%d' % (patch_name_1, grade_1, i_0, j_0, patch_name_2, grade_2, i_0, j_0), file=f_pout)\n",
        "                                    patch_name = '%s_patch_%d' % (name, j)\n",
        "                                    print('%s\\t%d\\t%d' % (patch_name, grade_1, grade_2), file=f_out)\n",
        "        f_out.close()\n",
        "        f_pout.close()\n",
        "\n",
        "    def count_gleason(self, tma_pref, csv_file, n_class=4):\n",
        "        print(\"count gleason train\",tma_pref)\n",
        "        f_out = open(csv_file, 'w')\n",
        "        print('%s\\t%s\\t%s' % ('TMA_spot', 'class_primary', 'class_secondary'), file=f_out)\n",
        "\n",
        "        # loop through all masks\n",
        "        for filename in os.listdir(self.path_masks):\n",
        "            if filename.startswith('mask_%s' % tma_pref):\n",
        "                key = filename.lstrip('mask_').rstrip('.png')\n",
        "                full_path = os.path.join(self.path_masks, filename)\n",
        "                primary_score, secondary_score = sum_up_gleason(full_path, n_class)\n",
        "                print('%s\\t%d\\t%d' % (key, primary_score, secondary_score), file=f_out)\n",
        "        f_out.close()\n",
        "\n",
        "    def count_gleason_joint(self, csv_file, n_class=4):\n",
        "        print(\"count gleason test\")\n",
        "        mask_dir_1 = os.path.join(self.path_masks, 'Gleason_masks_test_pathologist1')\n",
        "        mask_dir_2 = os.path.join(self.path_masks, 'Gleason_masks_test_pathologist2')\n",
        "\n",
        "        f_out = open(csv_file, 'w')\n",
        "        print('%s\\t%s\\t%s\\t%s\\t%s' % ('TMA_spot', 'patho1_class_primary', 'patho1_class_secondary',\n",
        "                                      'patho2_class_primary', 'patho2_class_secondary'), file=f_out)\n",
        "        # loop through all masks\n",
        "        for filename in os.listdir(mask_dir_1):\n",
        "            if filename.endswith('.png'):\n",
        "                key = filename.lstrip('mask1_').rstrip('.png')\n",
        "                # read the first pathologist's annotation\n",
        "                full_path_1 = os.path.join(mask_dir_1, filename)\n",
        "                primary_1, secondary_1 = sum_up_gleason(full_path_1, n_class)\n",
        "                # read the second pathologist's annotation\n",
        "                full_path_2 = os.path.join(mask_dir_2, 'mask2_'+key+'.png')\n",
        "                primary_2, secondary_2 = sum_up_gleason(full_path_2, n_class)\n",
        "                print('%s\\t%d\\t%d\\t%d\\t%d' % (key, primary_1, secondary_1, primary_2, secondary_2), file=f_out)\n",
        "        f_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebB1-OHjScD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    #change this for your path\n",
        "    prefix  = '/home/fabianleon/Documentos/gleason_CNN-master/dataset'\n",
        "    patch_size = 750\n",
        "    \n",
        "    # directory containing all TMA spot images\n",
        "    path_images = os.path.join(prefix, 'TMA_images')\n",
        "\n",
        "    # directory containing training labels (Gleason annotation masks by first pathologist)\n",
        "    path_train_masks = os.path.join(prefix, 'Gleason_masks_train')\n",
        "\n",
        "    # directory containing test labels (Gleason annotation masks by second pathologist)\n",
        "    path_test_masks = os.path.join(prefix, 'Gleason_masks_test')\n",
        "\n",
        "    # directory where summary intermediate files are saved\n",
        "    tma_info_path = os.path.join(prefix, 'tma_info')\n",
        "    if not os.path.exists(tma_info_path):\n",
        "        os.makedirs(tma_info_path)\n",
        "    # TMAs used for training/validation\n",
        "    tma_names = ['ZT76', 'ZT111', 'ZT199', 'ZT204']\n",
        "    tma_prefixes = ['ZT76_39', 'ZT111_4', 'ZT199_1', 'ZT204_6']\n",
        "    patch_size = 750\n",
        "    path_patches = os.path.join(prefix, 'train_validation_patches_%d' % patch_size)\n",
        "\n",
        "    # create patches and patch labels (training/validation sets)\n",
        "    for tma_name, tma_prefix in zip(tma_names, tma_prefixes):\n",
        "        proc = ImageProcessor(path_images, path_train_masks, path_patches)\n",
        "        pcvs_file = os.path.join(tma_info_path, '%s_pgleason_scores.csv' % tma_name)\n",
        "        proc.create_annotated_patches(pcvs_file,tma_prefix, patch_size=patch_size)\n",
        "        # write down a summary (primary and secondary Gleason patterns) of the annotation\n",
        "        csv_file = os.path.join(tma_info_path, '%s_gleason_scores.csv' % tma_name)\n",
        "        proc.count_gleason(tma_prefix, csv_file)\n",
        "    # TMAs used for testing\n",
        "    tma_name, tma_prefix = 'ZT80', 'ZT80_38'\n",
        "    path_test_patches = os.path.join(prefix, 'test_patches_%d' % patch_size)\n",
        "\n",
        "    # create patches for the test cohort (only use patches annotated by both pathologists)\n",
        "    joint_proc = ImageProcessor(path_images, path_test_masks, path_test_patches)\n",
        "    patch_file = os.path.join(tma_info_path, 'ZT80_patch_grades.csv')\n",
        "    pcvs_file = os.path.join(tma_info_path, 'ZT80_pgleason_scores.csv')\n",
        "    joint_proc.create_joint_patches(pcvs_file, tma_prefix, patch_size=patch_size, csv_file=patch_file)\n",
        "    csv_file = os.path.join(tma_info_path, '%s_gleason_scores.csv' % tma_name)\n",
        "    joint_proc.count_gleason_joint(csv_file)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}